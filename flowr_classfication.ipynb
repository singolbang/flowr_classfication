{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "\n",
    "# 폴더 경로 설정\n",
    "folder_path_train = 'train_path'\n",
    "folder_path_test = 'test_path'\n",
    "folder_path_val = 'val_path'\n",
    "\n",
    "\n",
    "# 이미지 데이터 증강을 위한 변환 설정\n",
    "\n",
    "transform_aug = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),      # 이미지 크기 조정\n",
    "    transforms.ColorJitter(brightness=0.3, saturation=0.3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),      # 이미지 크기 조정\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ImageFolder를 사용하여 데이터셋 생성 및 변환 적용\n",
    "dataset_train_DS = datasets.ImageFolder(folder_path_train, transform=transform_aug)\n",
    "dataset_train_DL = torch.utils.data.DataLoader(dataset_train_DS, batch_size=BATCH_SIZE, shuffle = True)\n",
    "\n",
    "dataset_test_DS = datasets.ImageFolder(folder_path_test, transform=transform)\n",
    "dataset_test_DL = torch.utils.data.DataLoader(dataset_test_DS, batch_size=BATCH_SIZE, shuffle = True)\n",
    "\n",
    "dataset_val_DS = datasets.ImageFolder(folder_path_val, transform=transform)\n",
    "dataset_val_DL = torch.utils.data.DataLoader(dataset_val_DS, batch_size=BATCH_SIZE, shuffle = True)\n",
    "\n",
    "\n",
    "img_tensor, label = dataset_train_DS[0]\n",
    "#print(dataset_train_DS[0][0])\n",
    "print(img_tensor.shape)\n",
    "\n",
    "print(len(dataset_test_DS))\n",
    "print(dataset_train_DS[0][0].shape)\n",
    "print(dataset_train_DS[0])\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "class DepSepconv(nn.Module):\n",
    "  def __init__(self, input_chanel, output_chanel, stride = 1, padding = 0):\n",
    "    super().__init__()\n",
    "\n",
    "    self.deptwise = nn.Sequential(nn.Conv2d(input_chanel, input_chanel, kernel_size = 1, stride = stride , padding = padding),\n",
    "                                  nn.BatchNorm2d(input_chanel), nn.ELU(inplace = True))\n",
    "\n",
    "\n",
    "    self.pointwise = nn.Sequential(nn.Conv2d(input_chanel, output_chanel, kernel_size = 1, bias = False),\n",
    "                                  nn.BatchNorm2d(output_chanel), nn.ELU(inplace = True))\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.deptwise(x)\n",
    "    x = self.pointwise(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class MobileNet_transform(nn.Module):\n",
    "  def __init__(self, alpha, num_classes):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1 = nn.Sequential(nn.Conv2d(3, int(32*alpha), kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                               nn.BatchNorm2d(int(32*alpha)),\n",
    "                               nn.ELU(inplace = True))\n",
    "\n",
    "    self.conv2 = nn.Sequential(DepSepconv(int(32*alpha), int(64*alpha)),\n",
    "                               DepSepconv(int(64*alpha), int(64*alpha)),\n",
    "                               nn.Conv2d(int(64*alpha), int(64*alpha), kernel_size = 2, stride = 2, bias = False),\n",
    "                               nn.BatchNorm2d(int(64*alpha)),\n",
    "                               nn.ELU(inplace = True))\n",
    "\n",
    "    self.conv3 = nn.Sequential(DepSepconv(int(64*alpha), int(128*alpha)),\n",
    "                               DepSepconv(int(128*alpha), int(128*alpha)),\n",
    "                               nn.Conv2d(int(128*alpha), int(128*alpha), kernel_size = 2, stride = 2, bias = False),\n",
    "                               nn.BatchNorm2d(int(128*alpha)),\n",
    "                               nn.ELU(inplace = True))\n",
    "\n",
    "    self.conv4 = nn.Sequential(DepSepconv(int(128*alpha), int(256*alpha)),\n",
    "                               DepSepconv(int(256*alpha), int(256*alpha)),\n",
    "                               nn.Conv2d(int(256*alpha), int(256*alpha), kernel_size = 2, stride = 2, bias = False),\n",
    "                               nn.BatchNorm2d(int(256*alpha)),\n",
    "                               nn.ELU(inplace = True))\n",
    "\n",
    "    self.conv5 = nn.Sequential(DepSepconv(int(256*alpha), int(512*alpha)),\n",
    "                               DepSepconv(int(512*alpha), int(512*alpha)),\n",
    "                               nn.Conv2d(int(512*alpha), int(512*alpha), kernel_size = 2, stride = 2, bias = False),\n",
    "                               nn.BatchNorm2d(int(512*alpha)),\n",
    "                               nn.ELU(inplace = True))\n",
    "\n",
    "    self.conv6 = nn.Sequential(DepSepconv(int(512*alpha), int(1024*alpha)),\n",
    "                               DepSepconv(int(1024*alpha), int(1024*alpha)))\n",
    "\n",
    "\n",
    "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "\n",
    "    self.fc = nn.Sequential(nn.Linear(int(1024*alpha), int(256*alpha)) , nn.ELU(inplace = True), nn.Dropout(p = 0.25),\n",
    "                            nn.Linear(int(256*alpha), int(256*alpha)), nn.ELU(inplace = True), nn.Dropout(p = 0.5),\n",
    "                            nn.Linear(int(256*alpha), int(64*alpha)), nn.ELU(inplace = True), nn.Dropout(p = 0.25),\n",
    "                            nn.Linear(int(64*alpha), num_classes))\n",
    "\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode = \"fan_in\", nonlinearity = \"relu\")\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.conv6(x)\n",
    "    x = self.avg_pool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "15063daf3f6080d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch, gc\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "epoch = 50\n",
    "LR = 0.0001\n",
    "errorfunc = nn.CrossEntropyLoss()\n",
    "\n",
    "def Train(model, train_DL, val_DL, criterion, optimizer, scheduler):\n",
    "\n",
    "  train_loss_set = []\n",
    "  train_acc_set = []\n",
    "\n",
    "  val_loss_set = []\n",
    "  val_acc_set = []\n",
    "\n",
    "  #Not = len(train_DL.dataset)\n",
    "  for e in range(epoch):\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = loss_epoch(model, train_DL, criterion, optimizer, scheduler)\n",
    "    train_loss_set = train_loss_set + [train_loss]\n",
    "    train_acc_set = train_acc_set + [train_acc]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss, val_acc = loss_epoch(model, val_DL, criterion)\n",
    "      val_loss_set = val_loss_set + [val_loss]\n",
    "      val_acc_set = val_acc_set + [val_acc]\n",
    "\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "    print(f\"epoch : {e+1}/{epoch}, train loss : {round(train_loss, 5)} , validation loss : {round(val_loss, 5)}, train accuracy : {round(train_acc, 2)}% , validation accuracy : {round(val_acc, 2)}%, time : {round(time.time() - epoch_start)}s\")\n",
    "    print(\"-\"*130)\n",
    "\n",
    "\n",
    "  loss_zip = [train_loss_set, val_loss_set]\n",
    "  acc_zip = [train_acc_set, val_acc_set]\n",
    "\n",
    "  return loss_zip, acc_zip\n",
    "\n",
    "\n",
    "def loss_epoch(model, DL, criterion, optimizer = None, scheduler = None):\n",
    "\n",
    "  Not = len(DL.dataset)\n",
    "  rloss = 0\n",
    "  rcorrect = 0\n",
    "  #print(e, rloss)\n",
    "  for x_batch, y_batch in tqdm(DL, leave = False):\n",
    "    x_batch = x_batch.to(DEVICE)\n",
    "    y_batch = y_batch.to(DEVICE)\n",
    "    y_hat = model(x_batch)\n",
    "    loss = criterion(y_hat, y_batch)\n",
    "    if optimizer is not None and scheduler is not None:\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward() #역전파\n",
    "      optimizer.step() #업데이트\n",
    "    loss_b = loss.item()*x_batch.shape[0]\n",
    "    rloss = rloss + loss_b\n",
    "    pred = y_hat.argmax(dim = 1)\n",
    "    correct_b = torch.sum(pred == y_batch).item()\n",
    "    rcorrect = rcorrect + correct_b\n",
    "    #print(rcorrect)\n",
    "  loss_e = rloss/Not\n",
    "  acc_e = rcorrect/Not*100\n",
    "\n",
    "  return loss_e, acc_e\n",
    "\n",
    "\n",
    "model = MobileNet_transform(0.85, 14).to(DEVICE)\n",
    "#load_model = MobileNet_transform(0.85, 14).to(DEVICE)\n",
    "#load_model.load_state_dict(torch.load(save_model_path, map_location = DEVICE))\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor=0.75, patience = 3)\n",
    "\n",
    "loss_history, acc_history = Train(model, dataset_train_DL, dataset_val_DL, errorfunc, optimizer, scheduler)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.plot(range(1, epoch+1), loss_history[0], label='train loss')\n",
    "ax1.plot(range(1, epoch+1), loss_history[1], label='validation loss')\n",
    "ax1.set_title('loss graph')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(range(1, epoch+1), acc_history[0], label='train accuracy')\n",
    "ax2.plot(range(1, epoch+1), acc_history[1], label='validation accuracy')\n",
    "ax2.set_title('accuracy graph')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "id": "81138692e7cdd67e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#print(DEVICE)\n",
    "def Test(model, test_DL):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    rcorrect = 0\n",
    "    for x_batch, y_batch in tqdm(test_DL, leave = False):\n",
    "      x_batch = x_batch.to(DEVICE)\n",
    "      y_batch = y_batch.to(DEVICE)\n",
    "      y_hat = model(x_batch)\n",
    "      #print(y_hat.shape)\n",
    "      pred = y_hat.argmax(dim=1)\n",
    "      #print(pred)\n",
    "      corrects_b = torch.sum(pred == y_batch).item()\n",
    "      rcorrect += corrects_b\n",
    "    accuracy = rcorrect/len(dataset_test_DL.dataset)*100\n",
    "  print(f\"Test accuracy : {rcorrect}/{len(dataset_test_DL.dataset)} ({round(accuracy, 2)}%)\")\n",
    "#print(pred == y_batch)\n",
    "#print(y_batch)\n",
    "\n",
    "\n",
    "def Test_plot(model, test_DL):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_batch, y_batch = next(iter(test_DL))\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_hat = model(x_batch)\n",
    "        pred = y_hat.argmax(dim=1)\n",
    "\n",
    "    x_batch = x_batch.to(\"cpu\")\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for idx in range(6):\n",
    "        plt.subplot(2,3, idx+1, xticks=[], yticks=[])\n",
    "        # 채행열 -> 행열채\n",
    "        plt.imshow(x_batch[idx].permute(1,2,0).squeeze(), cmap=\"gray\")\n",
    "        pred_class = test_DL.dataset.classes[pred[idx]]\n",
    "        true_class = test_DL.dataset.classes[y_batch[idx]]\n",
    "        plt.title(f\"{pred_class} ({true_class})\", color=\"g\" if pred_class==true_class else \"r\")\n",
    "\n",
    "def count_params(model):\n",
    "    num = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    return num\n",
    "\n"
   ],
   "id": "f8bc8b59364c959c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "Test(model, dataset_test_DL)\n",
    "#print(count_params(load_model))\n",
    "#Test(model, dataset_test_DL)\n",
    "\n",
    "Test_plot(model, dataset_test_DL)\n",
    "#Test_plot(model, dataset_test_DL)\n",
    "\n",
    "print(\"parameter : \", count_params(model))"
   ],
   "id": "5535ba61403c7376"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  for x_batch, y_batch in tqdm(dataset_test_DL, leave = True):\n",
    "    x_batch = x_batch.to(DEVICE)\n",
    "    y_batch = y_batch.to(DEVICE)\n",
    "    y_hat = model(x_batch)\n",
    "    pred = y_hat.argmax(dim=1)\n",
    "\n",
    "    y_hat = y_batch.to('cpu')\n",
    "    pred = pred.to('cpu')\n",
    "\n",
    "    y_hat = y_hat.tolist()\n",
    "    pred = pred.tolist()\n",
    "\n",
    "    y_true = y_true + y_hat\n",
    "    y_pred = y_pred + pred\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\n\")\n",
    "sns.heatmap(cm, annot = True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ],
   "id": "503542f3b8c60875"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
